{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIozR3MQXR-Z"
      },
      "source": [
        "# NLP X - HEC Embeddings session 4: Advanced Representations\n",
        "\n",
        "\n",
        "In this practical session, we will focus on word embeddings through word2vec, a simple and more advanced classification models for sentiment analysis (reviews ratings prediction). Once a negative sampling word2vec skipgram is trained, we can visualize learned word vectors in a reduced space and use them in our classification model.\n",
        "\n",
        "You will be asked to :\n",
        "1. **Train your own word embeddings with Skipgram** and Tensorflow using **Negative Sampling** method\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTopgfVKXc6S",
        "outputId": "74515a3f-96bf-45e0-f0db-68eaee0ccb72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_datasets\n",
            "  Downloading tensorflow_datasets-4.8.2-py3-none-any.whl (5.3 MB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.64.0)\n",
            "Requirement already satisfied: toml in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: absl-py in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.3.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (5.8.0)\n",
            "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (8.0.4)\n",
            "Collecting dm-tree\n",
            "  Downloading dm_tree-0.1.8-cp39-cp39-win_amd64.whl (101 kB)\n",
            "Collecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Requirement already satisfied: termcolor in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.2.0)\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
            "Requirement already satisfied: wrapt in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.12.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.19.1)\n",
            "Requirement already satisfied: dill in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.3.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.27.1)\n",
            "Collecting etils[enp,epath]>=0.9.0\n",
            "  Downloading etils-1.0.0-py3-none-any.whl (146 kB)\n",
            "Collecting importlib_resources\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: zipp in c:\\users\\dell\\anaconda3\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.7.0)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
            "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->tensorflow_datasets) (0.4.4)\n",
            "Requirement already satisfied: six in c:\\users\\dell\\anaconda3\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
            "Building wheels for collected packages: promise\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=929ad0c3c81da395c3144cd211f4aedc0e3d21dffed45385e14604253b3117a3\n",
            "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\e1\\e8\\83\\ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
            "Successfully built promise\n",
            "Installing collected packages: etils, importlib-resources, tensorflow-metadata, promise, dm-tree, tensorflow-datasets\n",
            "Successfully installed dm-tree-0.1.8 etils-1.0.0 importlib-resources-5.12.0 promise-2.3 tensorflow-datasets-4.8.2 tensorflow-metadata-1.12.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa65GC9hpmMq",
        "outputId": "d39ba2f9-e8a6-41d4-879b-caae21a22ae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NCdZHGP5CRw"
      },
      "source": [
        "### Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T128V6_AMxa",
        "outputId": "28888ee9-8845-407a-a250-f23b7003d397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Electric motors.gdoc',\n",
              " 'Bocconi Transcript.pdf',\n",
              " 'Ocean Carriers Calculations.gsheet',\n",
              " 'Kaan Caylan CV.pdf',\n",
              " 'Accounting Group Project',\n",
              " 'International Finance',\n",
              " 'Gilbert Strang - Introduction to Linear Algebra-Wellesley-Cambridge Press (2016).pdf',\n",
              " 'Contrat12moisGE (5) (2).pdf',\n",
              " 'Contrat12moisGE (5) (1).pdf',\n",
              " 'Contrat12moisGE (5) (1).gdoc',\n",
              " 'Translated copy of Contrat12moisGE (5) (1).gdoc',\n",
              " 'Contrat12moisGE (5).pdf',\n",
              " 'Contrat12moisGE (5).gdoc',\n",
              " 'Translated copy of Contrat12moisGE (5).gdoc',\n",
              " 'HEC Essay Questions.gdoc',\n",
              " 'Colab Notebooks',\n",
              " 'Master Courses DSB']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "### COMPLETE HERE ####\n",
        "## Path of directory on which your data is stored\n",
        "##dirpath = \" \"\n",
        "### END COMPLETE HERE ####\n",
        "\n",
        "dirpath = \"drive/MyDrive\" \n",
        "\n",
        "# get the list of files in the directory\n",
        "os.listdir(dirpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhrXXQNjXR-f"
      },
      "source": [
        "### Data collection and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPUEtBV2XR-d",
        "outputId": "93b90313-2ced-4394-b697-6c4265103c93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import re\n",
        "import tqdm\n",
        "import warnings\n",
        "import itertools\n",
        "from ast import literal_eval\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "from sklearn import decomposition\n",
        "import tensorflow as tf\n",
        "import sqlite3\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fa3bc49f1ca6448eb4e8faa3654621e7",
            "b38abd515fd6403d9b682c862c06a75c",
            "cb97f949f2c040ee8747a7c8a2f1169a",
            "6d6044c0426443ee994fbda41b39b052",
            "67b3454f23454e50b8f183e8a8152c53",
            "81b93f511fa745f7a9c8da41ba6b2bbf",
            "4695e9c1ff704fb69cfa5c205c9f86f4",
            "f6aaa5381fae49b49316cb8a7e4a778b",
            "5f5c54837b3e4377bc490279afd095f3",
            "bc4e35cf1bb542718c05aa70a60b150d",
            "73b31b162d4e48ac93a09b16e6f30a76"
          ]
        },
        "id": "j-b9jcroXR-e",
        "outputId": "d5dc2d49-af43-4464-ba66-ec1c4b31ca77"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a7568b661ae42ed88f9015d8585cb31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tqdm.tqdm_notebook().pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "BiMnFWMyIsTO"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page</th>\n",
              "      <th>titre</th>\n",
              "      <th>verbatim</th>\n",
              "      <th>date</th>\n",
              "      <th>note</th>\n",
              "      <th>reponse</th>\n",
              "      <th>date_experience</th>\n",
              "      <th>fournisseur</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Aucun soucis particulier</td>\n",
              "      <td>Je paie ma facture tous les deux mois en fonct...</td>\n",
              "      <td>Il y a 17 heures</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Date de l'expérience: 01 décembre 2022</td>\n",
              "      <td>https://fr.trustpilot.com/review/engie.fr</td>\n",
              "      <td>trustpilot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Engie facture a ses clients des sommes…</td>\n",
              "      <td>Engie facture a ses clients des sommes exorbit...</td>\n",
              "      <td>Il y a un jour</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonjour Julien Blanco,\\n\\nPour des raisons de ...</td>\n",
              "      <td>Date de l'expérience: 26 novembre 2022</td>\n",
              "      <td>https://fr.trustpilot.com/review/engie.fr</td>\n",
              "      <td>trustpilot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Facturation sur consommation d'un autre logement</td>\n",
              "      <td>Ils me facturent sur le pdl du logement au des...</td>\n",
              "      <td>ll y a 3 jours</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonjour BlooDz,\\n\\nPour des raisons de confide...</td>\n",
              "      <td>Date de l'expérience: 29 novembre 2022</td>\n",
              "      <td>https://fr.trustpilot.com/review/engie.fr</td>\n",
              "      <td>trustpilot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>un service client ou il est dur de…</td>\n",
              "      <td>un service client ou il est dur de comprendre ...</td>\n",
              "      <td>ll y a 3 jours</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonjour Ricanto77,\\nPour des raisons de confid...</td>\n",
              "      <td>Date de l'expérience: 29 novembre 2022</td>\n",
              "      <td>https://fr.trustpilot.com/review/engie.fr</td>\n",
              "      <td>trustpilot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Client d'ENGIE depuis longtemps toujours satis...</td>\n",
              "      <td>Excellente expérience avec ENGIE et une interl...</td>\n",
              "      <td>Il y a 24 minutes</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Date de l'expérience: 01 décembre 2022</td>\n",
              "      <td>https://fr.trustpilot.com/review/engie.fr</td>\n",
              "      <td>trustpilot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   page                                              titre  \\\n",
              "0     1                           Aucun soucis particulier   \n",
              "1     1            Engie facture a ses clients des sommes…   \n",
              "2     1   Facturation sur consommation d'un autre logement   \n",
              "3     1                un service client ou il est dur de…   \n",
              "4     1  Client d'ENGIE depuis longtemps toujours satis...   \n",
              "\n",
              "                                            verbatim               date  note  \\\n",
              "0  Je paie ma facture tous les deux mois en fonct...   Il y a 17 heures     4   \n",
              "1  Engie facture a ses clients des sommes exorbit...     Il y a un jour     1   \n",
              "2  Ils me facturent sur le pdl du logement au des...     ll y a 3 jours     1   \n",
              "3  un service client ou il est dur de comprendre ...     ll y a 3 jours     1   \n",
              "4  Excellente expérience avec ENGIE et une interl...  Il y a 24 minutes     5   \n",
              "\n",
              "                                             reponse  \\\n",
              "0                                                NaN   \n",
              "1  Bonjour Julien Blanco,\\n\\nPour des raisons de ...   \n",
              "2  Bonjour BlooDz,\\n\\nPour des raisons de confide...   \n",
              "3  Bonjour Ricanto77,\\nPour des raisons de confid...   \n",
              "4                                                NaN   \n",
              "\n",
              "                          date_experience  \\\n",
              "0  Date de l'expérience: 01 décembre 2022   \n",
              "1  Date de l'expérience: 26 novembre 2022   \n",
              "2  Date de l'expérience: 29 novembre 2022   \n",
              "3  Date de l'expérience: 29 novembre 2022   \n",
              "4  Date de l'expérience: 01 décembre 2022   \n",
              "\n",
              "                                 fournisseur      source  \n",
              "0  https://fr.trustpilot.com/review/engie.fr  trustpilot  \n",
              "1  https://fr.trustpilot.com/review/engie.fr  trustpilot  \n",
              "2  https://fr.trustpilot.com/review/engie.fr  trustpilot  \n",
              "3  https://fr.trustpilot.com/review/engie.fr  trustpilot  \n",
              "4  https://fr.trustpilot.com/review/engie.fr  trustpilot  "
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#filepath = os.path.join(dirpath, data_file) \n",
        "data_file = \"reviews.csv\"\n",
        "reviews = pd.read_csv(data_file, index_col=0)\n",
        "reviews.reset_index(inplace=True, drop=True)\n",
        "reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "R2at50mM6Z5S"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titre</th>\n",
              "      <th>verbatim</th>\n",
              "      <th>date</th>\n",
              "      <th>reponse</th>\n",
              "      <th>date_experience</th>\n",
              "      <th>fournisseur</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>37294</td>\n",
              "      <td>36314</td>\n",
              "      <td>37294</td>\n",
              "      <td>7972</td>\n",
              "      <td>37294</td>\n",
              "      <td>37294</td>\n",
              "      <td>37294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>11699</td>\n",
              "      <td>29565</td>\n",
              "      <td>21654</td>\n",
              "      <td>3867</td>\n",
              "      <td>3393</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Avis client</td>\n",
              "      <td>Très bien</td>\n",
              "      <td>le 01/12/2022 par Client.</td>\n",
              "      <td>Bonjour,</td>\n",
              "      <td>Réponse : Ohm Energie</td>\n",
              "      <td>https://www.avis-verifies.com/avis-clients/edf...</td>\n",
              "      <td>avis_verifies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>22971</td>\n",
              "      <td>518</td>\n",
              "      <td>153</td>\n",
              "      <td>1689</td>\n",
              "      <td>801</td>\n",
              "      <td>5080</td>\n",
              "      <td>22970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              titre   verbatim                       date   reponse  \\\n",
              "count         37294      36314                      37294      7972   \n",
              "unique        11699      29565                      21654      3867   \n",
              "top     Avis client  Très bien  le 01/12/2022 par Client.  Bonjour,   \n",
              "freq          22971        518                        153      1689   \n",
              "\n",
              "              date_experience  \\\n",
              "count                   37294   \n",
              "unique                   3393   \n",
              "top     Réponse : Ohm Energie   \n",
              "freq                      801   \n",
              "\n",
              "                                              fournisseur         source  \n",
              "count                                               37294          37294  \n",
              "unique                                                 19              2  \n",
              "top     https://www.avis-verifies.com/avis-clients/edf...  avis_verifies  \n",
              "freq                                                 5080          22970  "
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.describe(include=['O'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "1ekuwxVPngP_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(37294, 9)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "3Z_fV2NrXR-g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 37294 entries, 0 to 37293\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   page             37294 non-null  int64 \n",
            " 1   titre            37294 non-null  object\n",
            " 2   verbatim         36314 non-null  object\n",
            " 3   date             37294 non-null  object\n",
            " 4   note             37294 non-null  int64 \n",
            " 5   reponse          7972 non-null   object\n",
            " 6   date_experience  37294 non-null  object\n",
            " 7   fournisseur      37294 non-null  object\n",
            " 8   source           37294 non-null  object\n",
            "dtypes: int64(2), object(7)\n",
            "memory usage: 2.6+ MB\n"
          ]
        }
      ],
      "source": [
        "reviews.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkKDOc3XR-g"
      },
      "source": [
        "### Preprocessing & Understanding\n",
        "\n",
        "Let's visualize a review, contained in `content` column, then perform basic cleaning to get a proper text for each review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Je paie ma facture tous les deux mois en fonction de ma consommation exacte d'électricité. Cette facture tombe généralement en fin de mois, pile avant ma paie et j'ai donc constamment un peu moins d'une semaine de retard sur le paiement, mais mis a part un sms de rappel je n'ai jamais été harcelé par leurs services et ai même pu bénéficier une paire de fois d'un étalement des paiements quand j'en ai eu besoin. Leur service client est d'ailleurs généralement très agréable et compréhensif.\""
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.verbatim[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "_sWlaUBG7iDv"
      },
      "outputs": [],
      "source": [
        "def split_reviews_per_sentence(reviews, col ='verbatim' ):\n",
        "    reviews[\"review_sentences\"] = reviews[col].progress_apply(\n",
        "        lambda rvw: nltk.sent_tokenize(rvw)\n",
        "    )\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "bU0uCrDMXR-g"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(\"Je paie ma facture tous les deux mois en fonction de ma consommation exacte d'électricité. Cette facture tombe généralement en fin de mois, pile avant ma paie et j'ai donc constamment un peu moins d'une semaine de retard sur le paiement, mais mis a part un sms de rappel je n'ai jamais été harcelé par leurs services et ai même pu bénéficier une paire de fois d'un étalement des paiements quand j'en ai eu besoin. Leur service client est d'ailleurs généralement très agréable et compréhensif.\",\n",
              " str)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews['verbatim'][0], type(reviews['verbatim'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rmlV5XFYHRq5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.2.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "9aJbKQdFG4L0"
      },
      "outputs": [],
      "source": [
        "corpus = reviews['verbatim']\n",
        "import unidecode\n",
        "def preprocess_comment(comment):\n",
        "  corpus_l = comment.lower() \n",
        "\n",
        "  # In most of the case punctuation do not help on understanding a sentence or a doc\n",
        "  characters_to_remove = [\"@\", \"/\", \"#\", \".\", \",\", \"!\", \"?\", \"(\", \")\", \"-\", \"_\",\"’\",\"'\", \"\\\"\", \":\"]\n",
        "  transformation_dict = {initial:\" \" for initial in characters_to_remove}\n",
        "  no_punctuation_corpus = corpus_l.translate(str.maketrans(transformation_dict))\n",
        " \n",
        "  no_accent_corpus = unidecode.unidecode(no_punctuation_corpus)\n",
        "  clean_corpus = no_accent_corpus.replace(\"\\n\", \"\").replace(\"\\xa0\", \"\")\n",
        "  ## remove numbers \n",
        "  clean_corpus = ''.join([i for i in clean_corpus if not i.isdigit()])\n",
        "  \n",
        "  return clean_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Adh66SYy7wsg"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52676c28dbd34c38bf5555273a4b5b4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7972 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "1        [Engie facture a ses clients des sommes exorbi...\n",
              "2        [Ils me facturent sur le pdl du logement au de...\n",
              "3        [un service client ou il est dur de comprendre...\n",
              "5        [Service commercial déplorable dont on ne comp...\n",
              "6        [En cours de litige actuellement j attends des...\n",
              "                               ...                        \n",
              "37235    [comme toujours l'on ne comprend pas tout du p...\n",
              "37236               [on ne sait pas tout avec un seul RDV]\n",
              "37237                             [TROP CHERS MAIS SYMPAS]\n",
              "37267    [Demarche globale frauduleuse comme beaucoup d...\n",
              "37276    [Aucune explication sur les gains financiers d...\n",
              "Name: review_sentences, Length: 7972, dtype: object"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews =split_reviews_per_sentence(reviews.dropna(), col ='verbatim' )\n",
        "reviews[\"review_sentences\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Bwzfq806Fxkm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of total sentences : 25321\n"
          ]
        }
      ],
      "source": [
        "sentences = list(itertools.chain(*reviews[\"review_sentences\"]))\n",
        "print(f\"Number of total sentences : {len(sentences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Engie facture a ses clients des sommes exorbitants !',\n",
              " 'Engie mon facturer un technicien pour le gaz , alors que GRDF m’a bien préciser que le gaz était déjà en service dans mon logement !',\n",
              " 'Résultat des courses une facture de 71 euros juste pour ouvrir le compteur électrique de mon nouveau logement , concernant le gaz personne est intervenu sur ma chaudière j’ai dû le faire tout seul !',\n",
              " 'Engie savent prendre l’argent à tord mais quand ont leur explique malheureusement plus personne est là !']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.review_sentences[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "gpdgJc8RKCil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Engie facture a ses clients des sommes exorbitants !'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "n7E8ot1SJcbK"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "sentences = [preprocess_comment(comment) for comment in sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Blf_e6raQi"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_40i1E0V4Pz_"
      },
      "source": [
        "\n",
        "**Question** : plot the distribution of the number of sentences per review. <br>\n",
        "When handling sequential/textual data, input length may differ from a review to another. In Deep Learning, knowing input length distribution is important to perform zero-padding or truncating processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1        491\n",
              "2        343\n",
              "3        237\n",
              "5        655\n",
              "6        244\n",
              "        ... \n",
              "37235     56\n",
              "37236     36\n",
              "37237     22\n",
              "37267    667\n",
              "37276    372\n",
              "Name: verbatim, Length: 7972, dtype: int64"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.verbatim.apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Demarche globale frauduleuse comme beaucoup d'autres. Signature électronique de documents non lus une commande, un emprunt EDF ENR, achat et pose de materiels non definis. Ces pratiques ne sont pas à la gloire de cette entreprise qui se cache sous l'appellation EDF pour mettre en confiance. Peine perdue, tout a été annulé le lendemain de la visite à la lecture des documents transmis sans rapport avec la reunion de la veille. Pour un cout global deux fois plus élevé que tous les concurrents. Le credit gratuit EDF ENR est d'un coût très élevé. NE PAS RESPECTER LES CLIENTS NE PEUT QUE NUIRE A L'ENTREPRISE, sa disparition ne sera pas regrettée. Au plaisir, jpmarc\""
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.verbatim.loc[37267]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZH2Gw261XR-j"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: >"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "### FILL THE BLANK ###\n",
        "reviews[\"verbatim\"].apply(len).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "abmym9iUKl5B"
      },
      "outputs": [],
      "source": [
        "reviews[\"len_review_sentences\"]=reviews[\"verbatim\"].apply(len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcK4m9ZU0hdS"
      },
      "source": [
        "## Tokenization & Text Encoding\n",
        "This part concerns tokenization and text encoding with TensorFlow modules :\n",
        "\n",
        "*(i) Build the token vocabulary* <br>\n",
        "*(ii) Build a text encoder relying each word to an index, and thus each text to a sequence of word indices* (```list```) <br>\n",
        "*(iii) Build a TensorFlow dataset for word2vec training*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "clgWdmYXXR-j"
      },
      "outputs": [],
      "source": [
        "# Define and fit tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=' ', char_level=False)\n",
        "tokenizer.fit_on_texts(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLRUO4TahOtY"
      },
      "source": [
        "**Question** : use *texts_to_sequences* method of our tokenizer to get sequences from sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1        Engie facture a ses clients des sommes exorbit...\n",
              "2        Ils me facturent sur le pdl du logement au des...\n",
              "3        un service client ou il est dur de comprendre ...\n",
              "5        Service commercial déplorable dont on ne compr...\n",
              "6        En cours de litige actuellement j attends des ...\n",
              "                               ...                        \n",
              "37235    comme toujours l'on ne comprend pas tout du pr...\n",
              "37236                 on ne sait pas tout avec un seul RDV\n",
              "37237                               TROP CHERS MAIS SYMPAS\n",
              "37267    Demarche globale frauduleuse comme beaucoup d'...\n",
              "37276    Aucune explication sur les gains financiers de...\n",
              "Name: verbatim, Length: 7972, dtype: object"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews[\"verbatim\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0HTCETChKl2",
        "outputId": "15c073c6-6e4b-4715-b5f8-3ec51faf7809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E\n",
            "\n",
            "engie facture a ses clients des sommes exorbitants  \n",
            "\n",
            "[88, 48, 2, 230, 124, 19, 200, 1557]\n"
          ]
        }
      ],
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences) ### FILL THE BLANK ###\n",
        "print(reviews[\"verbatim\"][1][0], sentences[0], sequences[0], sep=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE3p7FbchlX6"
      },
      "source": [
        "**Question** : plot the distribution of the number of indices per sequence. <br>\n",
        "For the same reasons as above, it is important to know length distribution of sentences/sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-lAY2W09XR-k",
        "outputId": "f56f1e7a-256f-4ed4-ab08-f4adec06911b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAASQUlEQVR4nO3cf6zddX3H8edrreBvWuCGsLbZraHRVKPCGijRGEc3KGAsf6CBmNG5Zv1jddPNRMtMRqaSQLaIkilbI53FMCpDHY2g2BWMWSKFiyC/KnIFtG2AXmnBTSZafe+P86ke6720957bc8+1z0dycr7f9/fz/Z73uTnt63x/nG+qCknS0e33ZroBSdLMMwwkSYaBJMkwkCRhGEiSgLkz3cBUnXjiiTU8PDzTbUjSrHLPPff8qKqGDq7P2jAYHh5mZGRkptuQpFklyQ/Gq3uYSJJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJzOJfIPdieP0t49afuOL8PnciSYPhkHsGSTYm2ZPkwa7aPyb5bpL7k3w5ybyuZZcmGU3ySJJzuuorW200yfqu+uIk21v9C0mOmcb3J0k6DIdzmOhzwMqDaluBN1TVG4HvAZcCJFkKXAS8vq3zmSRzkswBPg2cCywFLm5jAa4ErqqqU4B9wJqe3pEkadIOGQZV9U1g70G1r1fV/jZ7J7CwTa8CNlfVC1X1ODAKnN4eo1X1WFX9DNgMrEoS4Czgprb+JuCC3t6SJGmypuME8p8DX23TC4CdXct2tdpE9ROAZ7uC5UB9XEnWJhlJMjI2NjYNrUuSoMcwSPIRYD9w/fS08+KqakNVLauqZUNDv3U7bknSFE35aqIkfwa8A1hRVdXKu4FFXcMWthoT1J8B5iWZ2/YOusdLkvpkSnsGSVYCHwLeWVXPdy3aAlyU5Ngki4ElwF3A3cCSduXQMXROMm9pIXIHcGFbfzVw89TeiiRpqg7n0tIbgG8Br02yK8ka4J+BVwFbk9yX5F8Aquoh4EbgYeBrwLqq+kX71v8+4DZgB3BjGwvwYeBvk4zSOYdw7bS+Q0nSIR3yMFFVXTxOecL/sKvqcuDyceq3AreOU3+MztVGkqQZ4u0oJEmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAksRhhEGSjUn2JHmwq3Z8kq1JHm3P81s9Sa5OMprk/iSnda2zuo1/NMnqrvofJnmgrXN1kkz3m5QkvbjD2TP4HLDyoNp6YFtVLQG2tXmAc4El7bEWuAY64QFcBpwBnA5cdiBA2pi/6Frv4NeSJB1hhwyDqvomsPeg8ipgU5veBFzQVb+uOu4E5iU5GTgH2FpVe6tqH7AVWNmWvbqq7qyqAq7r2pYkqU+mes7gpKp6sk0/BZzUphcAO7vG7Wq1F6vvGqc+riRrk4wkGRkbG5ti65Kkg/V8Arl9o69p6OVwXmtDVS2rqmVDQ0P9eElJOipMNQyebod4aM97Wn03sKhr3MJWe7H6wnHqkqQ+mmoYbAEOXBG0Gri5q35Ju6poOfBcO5x0G3B2kvntxPHZwG1t2Y+TLG9XEV3StS1JUp/MPdSAJDcAbwdOTLKLzlVBVwA3JlkD/AB4dxt+K3AeMAo8D7wXoKr2JvkYcHcb99GqOnBS+i/pXLH0MuCr7SFJ6qNDhkFVXTzBohXjjC1g3QTb2QhsHKc+ArzhUH1Iko4cf4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJHoMgyR/k+ShJA8muSHJS5MsTrI9yWiSLyQ5po09ts2PtuXDXdu5tNUfSXJOj+9JkjRJUw6DJAuAvwaWVdUbgDnARcCVwFVVdQqwD1jTVlkD7Gv1q9o4kixt670eWAl8JsmcqfYlSZq8Xg8TzQVelmQu8HLgSeAs4Ka2fBNwQZte1eZpy1ckSatvrqoXqupxYBQ4vce+JEmTMOUwqKrdwD8BP6QTAs8B9wDPVtX+NmwXsKBNLwB2tnX3t/EndNfHWec3JFmbZCTJyNjY2FRblyQdpJfDRPPpfKtfDPw+8Ao6h3mOmKraUFXLqmrZ0NDQkXwpSTqq9HKY6I+Bx6tqrKp+DnwJeAswrx02AlgI7G7Tu4FFAG35ccAz3fVx1pEk9cHcQw+Z0A+B5UleDvwfsAIYAe4ALgQ2A6uBm9v4LW3+W2357VVVSbYA/57kE3T2MJYAd/XQ15QNr79l3PoTV5zf504kqb+mHAZVtT3JTcC3gf3AvcAG4BZgc5KPt9q1bZVrgc8nGQX20rmCiKp6KMmNwMNtO+uq6hdT7UuSNHm97BlQVZcBlx1Ufoxxrgaqqp8C75pgO5cDl/fSiyRp6vwFsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNFjGCSZl+SmJN9NsiPJmUmOT7I1yaPteX4bmyRXJxlNcn+S07q2s7qNfzTJ6l7flCRpcnrdM/gU8LWqeh3wJmAHsB7YVlVLgG1tHuBcYEl7rAWuAUhyPHAZcAZwOnDZgQCRJPXHlMMgyXHA24BrAarqZ1X1LLAK2NSGbQIuaNOrgOuq405gXpKTgXOArVW1t6r2AVuBlVPtS5I0eb3sGSwGxoB/S3Jvks8meQVwUlU92cY8BZzUphcAO7vW39VqE9UlSX3SSxjMBU4DrqmqU4Gf8OtDQgBUVQHVw2v8hiRrk4wkGRkbG5uuzUrSUa+XMNgF7Kqq7W3+Jjrh8HQ7/EN73tOW7wYWda2/sNUmqv+WqtpQVcuqatnQ0FAPrUuSuk05DKrqKWBnkte20grgYWALcOCKoNXAzW16C3BJu6poOfBcO5x0G3B2kvntxPHZrSZJ6pO5Pa7/V8D1SY4BHgPeSydgbkyyBvgB8O429lbgPGAUeL6Npar2JvkYcHcb99Gq2ttjX5KkSegpDKrqPmDZOItWjDO2gHUTbGcjsLGXXiRJU+cvkCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLENIRBkjlJ7k3ylTa/OMn2JKNJvpDkmFY/ts2PtuXDXdu4tNUfSXJOrz1JkiZnOvYM3g/s6Jq/Eriqqk4B9gFrWn0NsK/Vr2rjSLIUuAh4PbAS+EySOdPQlyTpMPUUBkkWAucDn23zAc4CbmpDNgEXtOlVbZ62fEUbvwrYXFUvVNXjwChwei99SZImp9c9g08CHwJ+2eZPAJ6tqv1tfhewoE0vAHYCtOXPtfG/qo+zzm9IsjbJSJKRsbGxHluXJB0w5TBI8g5gT1XdM439vKiq2lBVy6pq2dDQUL9eVpJ+583tYd23AO9Mch7wUuDVwKeAeUnmtm//C4HdbfxuYBGwK8lc4Djgma76Ad3rSJL6YMp7BlV1aVUtrKphOieAb6+q9wB3ABe2YauBm9v0ljZPW357VVWrX9SuNloMLAHummpfkqTJ62XPYCIfBjYn+ThwL3Btq18LfD7JKLCXToBQVQ8luRF4GNgPrKuqXxyBviRJE5iWMKiqbwDfaNOPMc7VQFX1U+BdE6x/OXD5dPQiSZo8f4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiSOzO0ofucMr79l3PoTV5zf504k6chwz0CSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk0UMYJFmU5I4kDyd5KMn7W/34JFuTPNqe57d6klydZDTJ/UlO69rW6jb+0SSre39bkqTJ6GXPYD/wwapaCiwH1iVZCqwHtlXVEmBbmwc4F1jSHmuBa6ATHsBlwBnA6cBlBwJEktQfUw6Dqnqyqr7dpv8H2AEsAFYBm9qwTcAFbXoVcF113AnMS3IycA6wtar2VtU+YCuwcqp9SZImb1rOGSQZBk4FtgMnVdWTbdFTwEltegGws2u1Xa02UX2811mbZCTJyNjY2HS0LkliGsIgySuBLwIfqKofdy+rqgKq19fo2t6GqlpWVcuGhoama7OSdNTrKQySvIROEFxfVV9q5afb4R/a855W3w0s6lp9YatNVJck9UkvVxMFuBbYUVWf6Fq0BThwRdBq4Oau+iXtqqLlwHPtcNJtwNlJ5rcTx2e3miSpT+b2sO5bgD8FHkhyX6v9HXAFcGOSNcAPgHe3ZbcC5wGjwPPAewGqam+SjwF3t3Efraq9PfQlSZqkKYdBVf03kAkWrxhnfAHrJtjWRmDjVHuRJPXGXyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJInebkdx1Btef8u49SeuOL/PnUhSb9wzkCQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCW9HcUR4mwpJs417BpIkw0CSZBhIkvCcQV95LkHSoBqYMEiyEvgUMAf4bFVdMcMt9c1EIQEGhaT+GIgwSDIH+DTwJ8Au4O4kW6rq4ZntbOa5NyGpHwYiDIDTgdGqegwgyWZgFXDUh8FEXmxvYjIMFUkwOGGwANjZNb8LOOPgQUnWAmvb7P8meWSKr3ci8KMprjuTpr3vXDmdW3tR/s37a7b2DbO399nS9x+MVxyUMDgsVbUB2NDrdpKMVNWyaWipr2Zr3zB7e7fv/putvc/Wvg8YlEtLdwOLuuYXtpokqQ8GJQzuBpYkWZzkGOAiYMsM9yRJR42BOExUVfuTvA+4jc6lpRur6qEj+JI9H2qaIbO1b5i9vdt3/83W3mdr3wCkqma6B0nSDBuUw0SSpBlkGEiSjq4wSLIyySNJRpOsn+l+DpZkY5I9SR7sqh2fZGuSR9vz/FZPkqvbe7k/yWkz2PeiJHckeTjJQ0nePxt6T/LSJHcl+U7r+x9afXGS7a2/L7SLGkhybJsfbcuHZ6Lvrv7nJLk3yVdmWd9PJHkgyX1JRlptoD8rrZd5SW5K8t0kO5KcORv6PlxHTRh03fLiXGApcHGSpTPb1W/5HLDyoNp6YFtVLQG2tXnovI8l7bEWuKZPPY5nP/DBqloKLAfWtb/toPf+AnBWVb0JeDOwMsly4Ergqqo6BdgHrGnj1wD7Wv2qNm4mvR/Y0TU/W/oG+KOqenPXdfmD/lmBzr3TvlZVrwPeROdvPxv6PjxVdVQ8gDOB27rmLwUunem+xulzGHiwa/4R4OQ2fTLwSJv+V+Di8cbN9AO4mc59pmZN78DLgW/T+eX7j4C5B39u6FztdmabntvGZYb6XUjnP5+zgK8AmQ19tx6eAE48qDbQnxXgOODxg/9ug973ZB5HzZ4B49/yYsEM9TIZJ1XVk236KeCkNj2Q76cdgjgV2M4s6L0darkP2ANsBb4PPFtV+8fp7Vd9t+XPASf0teFf+yTwIeCXbf4EZkffAAV8Pck97RYzMPiflcXAGPBv7dDcZ5O8gsHv+7AdTWEw61XnK8bAXguc5JXAF4EPVNWPu5cNau9V9YuqejOdb9qnA6+b2Y4OLck7gD1Vdc9M9zJFb62q0+gcSlmX5G3dCwf0szIXOA24pqpOBX7Crw8JAQPb92E7msJgtt7y4ukkJwO05z2tPlDvJ8lL6ATB9VX1pVaeFb0DVNWzwB10Dq/MS3LgB5ndvf2q77b8OOCZ/nYKwFuAdyZ5AthM51DRpxj8vgGoqt3teQ/wZTohPOiflV3Arqra3uZvohMOg973YTuawmC23vJiC7C6Ta+mczz+QP2SdtXCcuC5rt3VvkoS4FpgR1V9omvRQPeeZCjJvDb9MjrnOXbQCYUL27CD+z7wfi4Ebm/fBvuqqi6tqoVVNUznc3x7Vb2HAe8bIMkrkrzqwDRwNvAgA/5ZqaqngJ1JXttKK+jcYn+g+56UmT5p0c8HcB7wPTrHhT8y0/2M098NwJPAz+l8E1lD59juNuBR4L+A49vY0Lk66vvAA8CyGez7rXR2j+8H7muP8wa9d+CNwL2t7weBv2/11wB3AaPAfwDHtvpL2/xoW/6aAfjMvB34ymzpu/X4nfZ46MC/w0H/rLRe3gyMtM/LfwLzZ0Pfh/vwdhSSpKPqMJEkaQKGgSTJMJAkGQaSJAwDSRKGgSQJw0CSBPw/8Bb3nMidhJcAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check the distribution of the number of indices per sequence\n",
        "### FILL THE BLANK ###\n",
        "plt.hist([len(sequence) for sequence in sequences], bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro2yYodZXR-k"
      },
      "source": [
        "# 1. Train our own word embeddings \n",
        "\n",
        "## Negative Sampling Skipgram\n",
        "Preprocessing function which generates skip-gram pairs with negative sampling for a list of sequences (int-encoded sentences) based on window size, number of negative samples and (tokenizer) vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "NGxcevNPXR-k"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14711"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Size of the vocabulary\n",
        "max(tokenizer.index_word.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4YLQmzAXR-k"
      },
      "source": [
        "## Generate training data for word2vec\n",
        "\n",
        "*(i) Define a sampling table for words in vocabulary, see [make_sampling_table](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/make_sampling_table)* <br>\n",
        "*(ii) For each sequence (tokenized/indexed sentence), run sliding process (window) and appropriate word sampling to build positive skip-gram word pairs* <br>\n",
        "*(iii) Iterate over each positive skip-gram pair to produce training examples with positive context word and negative samples, building corresponding labels.* <br>\n",
        "*(iv) Returns overall combinations of (target word, context word, negative words)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "zU3TWBxiXR-l"
      },
      "outputs": [],
      "source": [
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed=42):\n",
        "    # Elements of each training example are appended to these lists.\n",
        "    targets, contexts, labels = [], [], []\n",
        "\n",
        "    # Build the sampling table for vocab_size tokens.\n",
        "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "    # Iterate over all sequences (sentences) in dataset.\n",
        "    for sequence in tqdm.notebook.tqdm(sequences):\n",
        "\n",
        "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "            sequence, \n",
        "            vocabulary_size=vocab_size,\n",
        "            sampling_table=sampling_table,\n",
        "            window_size=window_size,\n",
        "            negative_samples=0\n",
        "        )\n",
        "\n",
        "        # Iterate over each positive skip-gram pair to produce training examples \n",
        "        # with positive context word and negative samples.\n",
        "        for target_word, context_word in positive_skip_grams:\n",
        "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "                true_classes=context_class,\n",
        "                num_true=1, \n",
        "                num_sampled=num_ns, \n",
        "                unique=True, \n",
        "                range_max=vocab_size, \n",
        "                seed=seed, \n",
        "                name=\"negative_sampling\"\n",
        "            )\n",
        "\n",
        "            # Build context and label vectors (for one target word)\n",
        "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
        "\n",
        "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
        "            label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "            # Append each element from the training example to global lists.\n",
        "            targets.append(target_word)\n",
        "            contexts.append(context)\n",
        "            labels.append(label)\n",
        "\n",
        "    return targets, contexts, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcdWsNb778TQ"
      },
      "source": [
        "**Question** : Build training data using ```window_size=2``` and number of negative samples per positive pair ```num_ns=4```. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "IwgqAlDbXR-l"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fccf780049349f3b7415cebd9a24863",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25321 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "210878 210878 210878\n"
          ]
        }
      ],
      "source": [
        "targets, contexts, labels = generate_training_data(\n",
        "    sequences=sequences, ### FILL THE BLANK ###\n",
        "    window_size=2, \n",
        "    num_ns=4, \n",
        "    vocab_size=max(tokenizer.index_word.keys())+1 ### FILL THE BLANK ### vocab size + 1 for padding\n",
        ")\n",
        "\n",
        "print(len(targets), len(contexts), len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "My6BD4zjz32w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1557\n",
            "\n",
            "tf.Tensor(\n",
            "[[  19]\n",
            " [ 376]\n",
            " [  31]\n",
            " [2321]\n",
            " [ 107]], shape=(5, 1), dtype=int64)\n",
            "\n",
            "tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "print(targets[0], contexts[0], labels[0], sep=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "0roqk2fkPRlb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'a quoi sert leur appli de suivi de consommation dans ce cas  et le service client au telephone    il pourrait etre representant en aspirateur ce serait la meme chose '"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Determine the tokenization index of target word, context word, and negative samples\n",
        "index_target =306\n",
        "index_context =2\n",
        "list_index_negative = [39, 3734, 143]\n",
        "### COMPLETE HERE #######\n",
        "### END COMPLETE HERE #######\n",
        "## Find the sequence related to targets[0], contexts[0]\n",
        "chosen_sequence = [i for i in sequences if index_target in i and index_context in i][0]\n",
        "\n",
        "# Find the index of the chosen_sequences in the sequences list\n",
        "index_sequence = sequences.index(chosen_sequence)\n",
        "\n",
        "## Find the sentence related to targets[0], contexts[0]\n",
        "sentences[index_sequence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "DyYw-QW_RpnL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target word :  chose\n",
            "Context word :  a\n",
            "Negative samples :  ['client', 'perdues', 'offre']\n"
          ]
        }
      ],
      "source": [
        "## Find the target word, the context word, and the negative samples\n",
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "print(\"Target word : \",reverse_word_map.get(index_target))\n",
        "print(\"Context word : \", reverse_word_map.get(index_context))\n",
        "print(\"Negative samples : \", [reverse_word_map.get(i) for i in list_index_negative])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "2sX_gC3jZHOO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "210878 210878 210878\n"
          ]
        }
      ],
      "source": [
        "print(len(targets), len(contexts), len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovE-2VTfXR-m"
      },
      "source": [
        "## Define TensorFlow dataset\n",
        "Define valid TensorFlow dataset from targets/contexts/labels iterable objects.\n",
        "Set two parameters : \n",
        "* *BUFFER_SIZE*\n",
        "* *BATCH_SIZE*\n",
        "\n",
        "*BATCH_SIZE* can be particularly important for making training efficient. Note that *BATCH_SIZE* must be obviously lower than dataset size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Scph45BfXR-m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int32, name=None), TensorSpec(shape=(1024, 5, 1), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "zblvr9RFWOPY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n",
            "size of targets :  (1024,)\n",
            "size of contexts :  (1024, 5, 1)\n",
            "size of labels :  (1024, 5)\n",
            "###############################\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for element in dataset.as_numpy_iterator():\n",
        "  a, label_array = element\n",
        "  target_array, context_array = a\n",
        "  print(\"size of targets : \", target_array.shape)\n",
        "  print(\"size of contexts : \",context_array.shape)\n",
        "  print(\"size of labels : \",label_array.shape)\n",
        "  print('###############################\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0TMNJXaXR-m"
      },
      "source": [
        "Define Skipgram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "bZA7iTnnXR-m"
      },
      "outputs": [],
      "source": [
        "class Skipgram(tf.keras.Model):\n",
        "    \"\"\"Negative Sampling Skigpram implementation.\n",
        "\n",
        "    ```python\n",
        "    w2v = Skipgram(vocab_size=4096, embedding_dim=128)\n",
        "    ````\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        \"\"\"Skigpram class constructor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        vocab_size: int.\n",
        "            Size of the vocabulary.\n",
        "\n",
        "        embedding_dim: int.\n",
        "            Dimension of trained word2vec Skipgram embeddings.\n",
        "\n",
        "        \"\"\"\n",
        "        super(Skipgram, self).__init__()\n",
        "        self.target_embedding = tf.keras.layers.Embedding(\n",
        "            vocab_size, \n",
        "            embedding_dim,\n",
        "            input_length=1,\n",
        "            name=\"w2v_embedding\",\n",
        "        )\n",
        "        self.context_embedding = tf.keras.layers.Embedding(\n",
        "            vocab_size, \n",
        "            embedding_dim, \n",
        "            input_length=4+1, # number of negative samples = 4\n",
        "            name=\"context_embedding\",\n",
        "        ) \n",
        "        self.dots = tf.keras.layers.Dot(axes=(3,1))\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "    def call(self, pair):\n",
        "        \"\"\"Model forward method.\n",
        "        \"\"\"\n",
        "        target, context = pair\n",
        "        we = self.target_embedding(target)\n",
        "        ce = self.context_embedding(context)\n",
        "        \n",
        "        dots = self.dots([ce, we])\n",
        "        \n",
        "        return self.flatten(dots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dnLCjOPXR-m"
      },
      "source": [
        "Define objective and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "v-zUEfd1XR-n"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 128\n",
        "\n",
        "word2vec = Skipgram(vocab_size=max(tokenizer.index_word.keys())+1, embedding_dim=128)\n",
        "word2vec.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Rfsnxesqgjca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "205/205 [==============================] - 21s 83ms/step - loss: 1.5962 - accuracy: 0.3106\n",
            "Epoch 2/20\n",
            "205/205 [==============================] - 17s 75ms/step - loss: 1.4600 - accuracy: 0.5093\n",
            "Epoch 3/20\n",
            "205/205 [==============================] - 17s 71ms/step - loss: 1.2752 - accuracy: 0.5655\n",
            "Epoch 4/20\n",
            "205/205 [==============================] - 18s 81ms/step - loss: 1.1181 - accuracy: 0.6285\n",
            "Epoch 5/20\n",
            "205/205 [==============================] - 16s 70ms/step - loss: 0.9870 - accuracy: 0.6805\n",
            "Epoch 6/20\n",
            "205/205 [==============================] - 19s 83ms/step - loss: 0.8783 - accuracy: 0.7231\n",
            "Epoch 7/20\n",
            "205/205 [==============================] - 17s 81ms/step - loss: 0.7868 - accuracy: 0.7573\n",
            "Epoch 8/20\n",
            "205/205 [==============================] - 15s 75ms/step - loss: 0.7093 - accuracy: 0.7850\n",
            "Epoch 9/20\n",
            "205/205 [==============================] - 16s 78ms/step - loss: 0.6430 - accuracy: 0.8081\n",
            "Epoch 10/20\n",
            "205/205 [==============================] - 15s 73ms/step - loss: 0.5860 - accuracy: 0.8270\n",
            "Epoch 11/20\n",
            "205/205 [==============================] - 15s 73ms/step - loss: 0.5369 - accuracy: 0.8430\n",
            "Epoch 12/20\n",
            "205/205 [==============================] - 15s 72ms/step - loss: 0.4940 - accuracy: 0.8565\n",
            "Epoch 13/20\n",
            "205/205 [==============================] - 16s 78ms/step - loss: 0.4573 - accuracy: 0.8686\n",
            "Epoch 14/20\n",
            "205/205 [==============================] - 15s 74ms/step - loss: 0.4252 - accuracy: 0.8785\n",
            "Epoch 15/20\n",
            "205/205 [==============================] - 15s 73ms/step - loss: 0.3969 - accuracy: 0.8877\n",
            "Epoch 16/20\n",
            "205/205 [==============================] - 15s 72ms/step - loss: 0.3719 - accuracy: 0.8956\n",
            "Epoch 17/20\n",
            "205/205 [==============================] - 15s 71ms/step - loss: 0.3499 - accuracy: 0.9021\n",
            "Epoch 18/20\n",
            "205/205 [==============================] - 15s 75ms/step - loss: 0.3303 - accuracy: 0.9076\n",
            "Epoch 19/20\n",
            "205/205 [==============================] - 15s 74ms/step - loss: 0.3128 - accuracy: 0.9131\n",
            "Epoch 20/20\n",
            "205/205 [==============================] - 14s 70ms/step - loss: 0.2971 - accuracy: 0.9175\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x15474b05460>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2vec.fit(dataset, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxRlDbjSXR-n"
      },
      "source": [
        "## Word Embeddings & Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcTRrWCbXR-n"
      },
      "source": [
        "word2vec.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QhfXxzdXR-n"
      },
      "outputs": [],
      "source": [
        "pretrained_weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
        "pretrained_weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBNoZhO9XR-n"
      },
      "source": [
        "Let's now visualize the embedding space, in 2 or 3 dimension. We could use a dimensionality reduction method such as PCA, T-SNE or UMAP.\n",
        "\n",
        "**Question** : after defining PCA object, use *fit_transform* method to get 3D-reduced vectors of word embeddings for visualization and print explained variance ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0CCxOq9XR-o"
      },
      "outputs": [],
      "source": [
        "def do_pca(pretrained_weights):\n",
        "    pca = decomposition.PCA(n_components=3)\n",
        "    reduced_weights = pca.fit_transform(pretrained_weights) ### FILL THE BLANK ###\n",
        "    return pca, reduced_weights\n",
        "\n",
        "pca, reduced_weights = do_pca(pretrained_weights)\n",
        "print(reduced_weights.shape)\n",
        "print(pca.explained_variance_ratio_) ### FILL THE BLANK ### # explained variance ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulGYQw6sXR-o"
      },
      "outputs": [],
      "source": [
        "df_pca = pd.DataFrame(data=reduced_weights, columns=[\"pca_1\", \"pca_2\", \"pca_3\"])\n",
        "df_pca[\"word\"] = [\"<pad>\"] + list(tokenizer.word_index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLMFvU7hXR-o"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter_3d(\n",
        "    df_pca, \n",
        "    x=\"pca_1\", \n",
        "    y=\"pca_2\", \n",
        "    z=\"pca_3\",\n",
        "    hover_name=\"word\",\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "fig.update_layout(height=700, width=700)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXGgOQblvqB0"
      },
      "source": [
        "## Similarities "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTAMxnSxvsJc"
      },
      "outputs": [],
      "source": [
        "pretrained_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8A4dsAwOtYA"
      },
      "outputs": [],
      "source": [
        "tokenizer.index_word.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1IWGDqgvscY"
      },
      "outputs": [],
      "source": [
        "words =[]\n",
        "vectors =[]\n",
        "for idx, word in tokenizer.index_word.items():\n",
        "  vec = pretrained_weights[idx] # first idx is 1 : skip 0, it's padding.\n",
        "  words.append(word)\n",
        "  vectors.append(vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xywdVhYNOOQq"
      },
      "outputs": [],
      "source": [
        "len(tokenizer.index_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCsm6XCiOMp4"
      },
      "outputs": [],
      "source": [
        "pretrained_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzvesynaxaWG"
      },
      "outputs": [],
      "source": [
        "word = 'soleil' \n",
        "index_word = words.index(word)\n",
        "print(index_word)\n",
        "vec_word = vectors[index_word]\n",
        "print(vec_word.shape)\n",
        "dis_to_word={}\n",
        "for idx in range(len(vectors)):\n",
        "  dis_to_word[idx]= np.linalg.norm(vec_word-vectors[idx])\n",
        "sorted_dis_to_word = {k: v for k, v in sorted(dis_to_word.items(), key=lambda item: item[1])}\n",
        "list(sorted_dis_to_word.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVaKx70Dy4DN"
      },
      "outputs": [],
      "source": [
        "for idx in list(sorted_dis_to_word.keys())[:10]:\n",
        "  print(words[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OE0RjGD7a2b"
      },
      "source": [
        "## Limitations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlMKbFgp25p0"
      },
      "source": [
        "### Zoom on limitation : Ignoring the intrinsic structure of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr0g-6aY2hWM"
      },
      "outputs": [],
      "source": [
        "word = 'borne' \n",
        "index_word = words.index(word)\n",
        "print(index_word)\n",
        "vec_word_1 = vectors[index_word]\n",
        "\n",
        "word = 'bornes' \n",
        "index_word = words.index(word)\n",
        "print(index_word)\n",
        "vec_word_2 = vectors[index_word]\n",
        "\n",
        "\n",
        "print(np.linalg.norm(vec_word_1-vec_word_2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUFi9kUSJYYx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_-Blf_e6raQi",
        "tcK4m9ZU0hdS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "a2ab3825ac7005fb7b26f112e9c99ae62f464c629e30b0d534c3b931b6cbc3ff"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4695e9c1ff704fb69cfa5c205c9f86f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f5c54837b3e4377bc490279afd095f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b3454f23454e50b8f183e8a8152c53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6044c0426443ee994fbda41b39b052": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc4e35cf1bb542718c05aa70a60b150d",
            "placeholder": "​",
            "style": "IPY_MODEL_73b31b162d4e48ac93a09b16e6f30a76",
            "value": " 0/? [00:42&lt;?, ?it/s]"
          }
        },
        "73b31b162d4e48ac93a09b16e6f30a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b93f511fa745f7a9c8da41ba6b2bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38abd515fd6403d9b682c862c06a75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b93f511fa745f7a9c8da41ba6b2bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_4695e9c1ff704fb69cfa5c205c9f86f4",
            "value": ""
          }
        },
        "bc4e35cf1bb542718c05aa70a60b150d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb97f949f2c040ee8747a7c8a2f1169a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6aaa5381fae49b49316cb8a7e4a778b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f5c54837b3e4377bc490279afd095f3",
            "value": 0
          }
        },
        "f6aaa5381fae49b49316cb8a7e4a778b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fa3bc49f1ca6448eb4e8faa3654621e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b38abd515fd6403d9b682c862c06a75c",
              "IPY_MODEL_cb97f949f2c040ee8747a7c8a2f1169a",
              "IPY_MODEL_6d6044c0426443ee994fbda41b39b052"
            ],
            "layout": "IPY_MODEL_67b3454f23454e50b8f183e8a8152c53"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
