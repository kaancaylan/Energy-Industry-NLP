{"cells":[{"cell_type":"markdown","metadata":{"id":"jDEypOOmItyi"},"source":["# Grade prediction with BERT embedding"]},{"cell_type":"markdown","metadata":{"id":"XnT4HuX7JUGE"},"source":["In this notebook, we will use pre-trained deep learning model to process some text. We will then use the output of that model to classify the reviews we scrapped in previous courses. We will try to predict wether it was positive or negative. "]},{"cell_type":"markdown","metadata":{"id":"0nzNnspoKQYQ"},"source":["Under the hood, the model is actually made up of two model.\n","\n","\n","1.   DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n","2.   The next model, a basic Logistic Regression model from scikit learn will identify if the review was positive or negative\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qJjqAYOsKilN"},"source":["## Installing the transformers library\n","\n","Let's start by installing the huggingface transformers library so we can load our deep learning NLP model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1e_arZkIUql"},"outputs":[],"source":["# The transformers library is already installed\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","from scipy.stats import loguniform\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"EFuqcJkdK3Wg"},"source":["## Importing the dataset\n","\n","We'll import the dataset as we did in previous notebooks:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXLMU3WtIUqm"},"outputs":[],"source":["reviews = pd.read_csv('reviews.csv')\n","reviews.drop(columns=[\"Unnamed: 0\"], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GG8yiP7IUqm","outputId":"99b91bad-0251-45f9-d74b-81edd49cb6ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 37294 entries, 0 to 37293\n","Data columns (total 9 columns):\n"," #   Column           Non-Null Count  Dtype \n","---  ------           --------------  ----- \n"," 0   page             37294 non-null  int64 \n"," 1   titre            37294 non-null  object\n"," 2   verbatim         36314 non-null  object\n"," 3   date             37294 non-null  object\n"," 4   note             37294 non-null  int64 \n"," 5   reponse          7972 non-null   object\n"," 6   date_experience  37294 non-null  object\n"," 7   fournisseur      37294 non-null  object\n"," 8   source           37294 non-null  object\n","dtypes: int64(2), object(7)\n","memory usage: 2.6+ MB\n"]}],"source":["reviews.info()"]},{"cell_type":"markdown","metadata":{"id":"_-QTwUjyMaug"},"source":["In the first place we should determine what are we considering a positive review. In this case we shall consider as positive every comment that had 4 or 5 as grade and negative otherwise."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wANfFzAMIUqm"},"outputs":[],"source":["# ASSIGN A LABEL TO EACH REVIEW TO DIFFERENCITATE POSITIVE AND NEGATIVE REVIEWS\n","reviews['sentiment'] = reviews.note.apply(lambda x: 'pos' if x >= 4 else 'neg')\n","\n","# REMOVE REVIEWS WITH NULL VALUES\n","reviews.dropna(inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"NmTcdISzM9so"},"source":["For computational purposes, we'll only use 1000 sentences which have less than 100 words in it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zh-vkDiMNtwB","outputId":"05829381-2ee8-4689-b5d5-bf24c8698a54"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>page</th>\n","      <th>titre</th>\n","      <th>verbatim</th>\n","      <th>date</th>\n","      <th>note</th>\n","      <th>reponse</th>\n","      <th>date_experience</th>\n","      <th>fournisseur</th>\n","      <th>source</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>208</td>\n","      <td>honteux</td>\n","      <td>Tres bien et facile pour obtenir un contrat, p...</td>\n","      <td>27 mai 2020</td>\n","      <td>1</td>\n","      <td>Bonjour Marina,\\n\\nJe suis navré d'apprendre q...</td>\n","      <td>Date de l'expérience: 27 mai 2020</td>\n","      <td>https://fr.trustpilot.com/review/totalenergies.fr</td>\n","      <td>trustpilot</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>61</td>\n","      <td>Bon service</td>\n","      <td>Ohm , services clients satisfaisant.</td>\n","      <td>19 janv. 2022</td>\n","      <td>5</td>\n","      <td>Bonjour,\\nNous sommes très touchés que votre p...</td>\n","      <td>Date de l'expérience: 19 janvier 2022</td>\n","      <td>https://fr.trustpilot.com/review/ohm-energie.com</td>\n","      <td>trustpilot</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>313</td>\n","      <td>Avis client</td>\n","      <td>J'ai etait prévenu assez tard qu'il fallait un...</td>\n","      <td>le 06/10/2022 par ELODIE D.</td>\n","      <td>2</td>\n","      <td>Bonjour,</td>\n","      <td>suite à une expérience du 27/09/2022</td>\n","      <td>https://www.avis-verifies.com/avis-clients/tot...</td>\n","      <td>avis_verifies</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22</td>\n","      <td>Avis client</td>\n","      <td>C'est très bien je suis très à l'aise avec eux</td>\n","      <td>le 26/09/2021 par ZAKARIA H.</td>\n","      <td>5</td>\n","      <td>Bonjour,</td>\n","      <td>suite à une expérience du 24/04/2021</td>\n","      <td>https://www.avis-verifies.com/avis-clients/fr....</td>\n","      <td>avis_verifies</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358</td>\n","      <td>Avis client</td>\n","      <td>Prix bien trop cher, montages financiers douteux.</td>\n","      <td>le 02/10/2022 par ALEXANDRE V.</td>\n","      <td>1</td>\n","      <td>Commentaire de TotalEnergies\\nBonjour,\\n\\nJ'ai...</td>\n","      <td>suite à une expérience du 23/09/2022</td>\n","      <td>https://www.avis-verifies.com/avis-clients/tot...</td>\n","      <td>avis_verifies</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>405</td>\n","      <td>Avis client</td>\n","      <td>...</td>\n","      <td>le 29/09/2022 par RAPHAËLLE B.</td>\n","      <td>5</td>\n","      <td>Bonjour,</td>\n","      <td>suite à une expérience du 16/09/2022</td>\n","      <td>https://www.avis-verifies.com/avis-clients/tot...</td>\n","      <td>avis_verifies</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>347</td>\n","      <td>Avis client</td>\n","      <td>Horrible</td>\n","      <td>le 03/10/2022 par ANISSA L.</td>\n","      <td>1</td>\n","      <td>Bonjour Madame,</td>\n","      <td>suite à une expérience du 23/09/2022</td>\n","      <td>https://www.avis-verifies.com/avis-clients/tot...</td>\n","      <td>avis_verifies</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>103</td>\n","      <td>Bonne Expérience avec Ohm Energie</td>\n","      <td>Bonne Expérience avec Ohm Energie . Bonne acco...</td>\n","      <td>14 juin 2021</td>\n","      <td>5</td>\n","      <td>Bonjour,\\nNous sommes ravis que nos services a...</td>\n","      <td>Date de l'expérience: 14 juin 2021</td>\n","      <td>https://fr.trustpilot.com/review/ohm-energie.com</td>\n","      <td>trustpilot</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>461</td>\n","      <td>Avis client</td>\n","      <td>L'offre que j'ai souscrite \"essentielle\" est u...</td>\n","      <td>le 25/09/2022 par GREGORY B.</td>\n","      <td>2</td>\n","      <td>Bonjour,</td>\n","      <td>suite à une expérience du 10/09/2022</td>\n","      <td>https://www.avis-verifies.com/avis-clients/tot...</td>\n","      <td>avis_verifies</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>175</td>\n","      <td>Avis client</td>\n","      <td>Maintenant j'attends la suite : avis des autor...</td>\n","      <td>le 13/09/2022 par Jean-pierre B.</td>\n","      <td>3</td>\n","      <td>Commentaire de EDF ENR\\nBonjour Monsieur,\\n\\nJ...</td>\n","      <td>suite à une expérience du 11/08/2022</td>\n","      <td>https://www.avis-verifies.com/avis-clients/edf...</td>\n","      <td>avis_verifies</td>\n","      <td>neg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 10 columns</p>\n","</div>"],"text/plain":["     page                              titre  \\\n","0     208                            honteux   \n","1      61                        Bon service   \n","2     313                        Avis client   \n","3      22                        Avis client   \n","4     358                        Avis client   \n","..    ...                                ...   \n","995   405                        Avis client   \n","996   347                        Avis client   \n","997   103  Bonne Expérience avec Ohm Energie   \n","998   461                        Avis client   \n","999   175                        Avis client   \n","\n","                                              verbatim  \\\n","0    Tres bien et facile pour obtenir un contrat, p...   \n","1                 Ohm , services clients satisfaisant.   \n","2    J'ai etait prévenu assez tard qu'il fallait un...   \n","3       C'est très bien je suis très à l'aise avec eux   \n","4    Prix bien trop cher, montages financiers douteux.   \n","..                                                 ...   \n","995                                                ...   \n","996                                           Horrible   \n","997  Bonne Expérience avec Ohm Energie . Bonne acco...   \n","998  L'offre que j'ai souscrite \"essentielle\" est u...   \n","999  Maintenant j'attends la suite : avis des autor...   \n","\n","                                 date  note  \\\n","0                         27 mai 2020     1   \n","1                       19 janv. 2022     5   \n","2         le 06/10/2022 par ELODIE D.     2   \n","3        le 26/09/2021 par ZAKARIA H.     5   \n","4      le 02/10/2022 par ALEXANDRE V.     1   \n","..                                ...   ...   \n","995    le 29/09/2022 par RAPHAËLLE B.     5   \n","996       le 03/10/2022 par ANISSA L.     1   \n","997                      14 juin 2021     5   \n","998      le 25/09/2022 par GREGORY B.     2   \n","999  le 13/09/2022 par Jean-pierre B.     3   \n","\n","                                               reponse  \\\n","0    Bonjour Marina,\\n\\nJe suis navré d'apprendre q...   \n","1    Bonjour,\\nNous sommes très touchés que votre p...   \n","2                                             Bonjour,   \n","3                                             Bonjour,   \n","4    Commentaire de TotalEnergies\\nBonjour,\\n\\nJ'ai...   \n","..                                                 ...   \n","995                                           Bonjour,   \n","996                                    Bonjour Madame,   \n","997  Bonjour,\\nNous sommes ravis que nos services a...   \n","998                                           Bonjour,   \n","999  Commentaire de EDF ENR\\nBonjour Monsieur,\\n\\nJ...   \n","\n","                           date_experience  \\\n","0        Date de l'expérience: 27 mai 2020   \n","1    Date de l'expérience: 19 janvier 2022   \n","2     suite à une expérience du 27/09/2022   \n","3     suite à une expérience du 24/04/2021   \n","4     suite à une expérience du 23/09/2022   \n","..                                     ...   \n","995   suite à une expérience du 16/09/2022   \n","996   suite à une expérience du 23/09/2022   \n","997     Date de l'expérience: 14 juin 2021   \n","998   suite à une expérience du 10/09/2022   \n","999   suite à une expérience du 11/08/2022   \n","\n","                                           fournisseur         source  \\\n","0    https://fr.trustpilot.com/review/totalenergies.fr     trustpilot   \n","1     https://fr.trustpilot.com/review/ohm-energie.com     trustpilot   \n","2    https://www.avis-verifies.com/avis-clients/tot...  avis_verifies   \n","3    https://www.avis-verifies.com/avis-clients/fr....  avis_verifies   \n","4    https://www.avis-verifies.com/avis-clients/tot...  avis_verifies   \n","..                                                 ...            ...   \n","995  https://www.avis-verifies.com/avis-clients/tot...  avis_verifies   \n","996  https://www.avis-verifies.com/avis-clients/tot...  avis_verifies   \n","997   https://fr.trustpilot.com/review/ohm-energie.com     trustpilot   \n","998  https://www.avis-verifies.com/avis-clients/tot...  avis_verifies   \n","999  https://www.avis-verifies.com/avis-clients/edf...  avis_verifies   \n","\n","    sentiment  \n","0         neg  \n","1         pos  \n","2         neg  \n","3         pos  \n","4         neg  \n","..        ...  \n","995       pos  \n","996       neg  \n","997       pos  \n","998       neg  \n","999       neg  \n","\n","[1000 rows x 10 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Filter the reviews\n","reviews['verbatim'] = reviews.verbatim.apply(lambda x: x if len(x.split(' ')) <= 100 else np.nan)\n","reviews.dropna(inplace=True)\n","reviews = reviews.sample(1000)\n","reviews.reset_index(inplace=True, drop=True)\n","reviews"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rEDUy9pIIUqo"},"outputs":[],"source":["#Save in two variables the comments and the labels\n","sentences = reviews['verbatim'].values\n","labels = reviews['sentiment'].values"]},{"cell_type":"markdown","metadata":{"id":"PhTEgAgqNuH4"},"source":["## Loading the Pre-trained BERT model\n","Let's now load a pre-trained BERT model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MX4O0N4TKhwe","outputId":"f119e687-1cff-46ad-da1b-2b916f4434b7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# For DistilBERT:\n","model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n","\n","# Load pretrained model/tokenizer\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)"]},{"cell_type":"markdown","metadata":{"id":"-ph0mRppN-F5"},"source":["Right now, the variable model holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory."]},{"cell_type":"markdown","metadata":{"id":"RIL8EBl2OFky"},"source":["# Model 1: Preparing the Dataset\n","Before we can hand our sentences to BERT, we need to do some minimal processing to put them in the format it requires."]},{"cell_type":"markdown","metadata":{"id":"JBRoghfCOL6Z"},"source":["### Tokenization\n","Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FD6VIbtjIUqo"},"outputs":[],"source":["# Apply tokenization\n","tokenized = [tokenizer(sentence) for sentence in sentences]"]},{"cell_type":"markdown","metadata":{"id":"gIryhAglOZeR"},"source":["### Padding\n","After tokenization, tokenized is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYnH9rohIUqp"},"outputs":[],"source":["# Perform the padding\n","max_len = 0\n","\n","for t in tokenized:\n","    if len(t['input_ids']) > max_len:\n","        max_len = len(t['input_ids'])\n","\n","padded = np.array([t['input_ids'] + [0] * (max_len - len(t['input_ids'])) for t in tokenized])"]},{"cell_type":"markdown","metadata":{"id":"tbCa9CsCOmSe"},"source":["Our dataset is now in the padded variable, we can view its dimensions below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hICAGTYdIUqp","outputId":"6478bfc6-0c41-4094-c836-a1ee365c6c08"},"outputs":[{"data":{"text/plain":["(1000, 217)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["padded.shape"]},{"cell_type":"markdown","metadata":{"id":"LpL42j8IOvfc"},"source":["### Masking\n","If we directly send padded to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NB1k1ZeMIUqp","outputId":"78701449-4483-485f-d4f1-4f88d0c0ae62"},"outputs":[{"data":{"text/plain":["(1000, 217)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["attention_mask = np.where(padded != 0, 1, 0)\n","attention_mask.shape"]},{"cell_type":"markdown","metadata":{"id":"TGr2t2V2O-bU"},"source":["## Model 1: And Now, Deep Learning!\n","Now that we have our model and inputs ready, let's run our model! \n","\n","The model() function runs our sentences through BERT. The results of the processing will be returned into last_hidden_states."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ARJnQ8eOIUqp"},"outputs":[],"source":["input_ids = torch.tensor(padded)  \n","attention_mask = torch.tensor(attention_mask)\n","\n","with torch.no_grad():\n","    last_hidden_states = model(input_ids, attention_mask=attention_mask)"]},{"cell_type":"markdown","metadata":{"id":"uMo4SpXiPY30"},"source":["Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called [CLS] (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n","\n","We'll save those in the features variable, as they'll serve as the features to our logitics regression model.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3nPR2mrIUqq"},"outputs":[],"source":["features = last_hidden_states[0][:,0,:].numpy()"]},{"cell_type":"markdown","metadata":{"id":"cne1LmgZPyQP"},"source":["## Model 2: Train/Test Split\n","Let's now split our datset into a training set and testing set (even though we're using 1,000 sentences from the reviews training set)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EfDqA84TU_4"},"outputs":[],"source":["# Split the data in train and test with the train_test_split function\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"gDc9UFa5P_8G"},"source":["## [Bonus] Grid Search for Parameters\n","We can dive into Logistic regression directly with the Scikit Learn default parameters, but sometimes it's worth searching for the best value of the C parameter, which determines regularization strength."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xg1yURnlQDRD","outputId":"57767212-9446-4e17-d900-d4c3428613b0"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n","             param_grid={&#x27;C&#x27;: array([3.41349058e+00, 8.12125219e-05, 2.79301940e+00, 4.82111370e-02,\n","       7.33725967e-03, 6.84815584e-03, 3.56461660e-04, 4.56614485e-04,\n","       1.31019690e-04, 2.25346474e+01, 5.17810369e-05, 2.27373696e-02,\n","       1.28920093e+00, 1.39458291e-03, 2.73032607e-02, 6.19396894e-04,\n","       9.37874966e-02, 7.13676378e+01, 2.549970...\n","       1.80541839e-05, 1.38445205e+00, 2.42294898e-05, 1.92992532e+00,\n","       3.29686208e+01, 5.28199561e-03, 3.13283014e-05, 1.70559678e-02,\n","       8.00723392e+01, 4.15799422e-02, 5.49151100e-03, 2.71379372e+01,\n","       3.28577885e-02, 1.76598278e-01, 2.41057562e-05, 1.84555548e-05,\n","       2.42000292e-05, 6.84486965e-03, 4.19723119e+00, 2.74593676e-02,\n","       2.38679011e+00, 7.37128542e-02, 9.39987999e-02, 4.96891052e-02])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n","             param_grid={&#x27;C&#x27;: array([3.41349058e+00, 8.12125219e-05, 2.79301940e+00, 4.82111370e-02,\n","       7.33725967e-03, 6.84815584e-03, 3.56461660e-04, 4.56614485e-04,\n","       1.31019690e-04, 2.25346474e+01, 5.17810369e-05, 2.27373696e-02,\n","       1.28920093e+00, 1.39458291e-03, 2.73032607e-02, 6.19396894e-04,\n","       9.37874966e-02, 7.13676378e+01, 2.549970...\n","       1.80541839e-05, 1.38445205e+00, 2.42294898e-05, 1.92992532e+00,\n","       3.29686208e+01, 5.28199561e-03, 3.13283014e-05, 1.70559678e-02,\n","       8.00723392e+01, 4.15799422e-02, 5.49151100e-03, 2.71379372e+01,\n","       3.28577885e-02, 1.76598278e-01, 2.41057562e-05, 1.84555548e-05,\n","       2.42000292e-05, 6.84486965e-03, 4.19723119e+00, 2.74593676e-02,\n","       2.38679011e+00, 7.37128542e-02, 9.39987999e-02, 4.96891052e-02])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["GridSearchCV(cv=3, estimator=LogisticRegression(),\n","             param_grid={'C': array([3.41349058e+00, 8.12125219e-05, 2.79301940e+00, 4.82111370e-02,\n","       7.33725967e-03, 6.84815584e-03, 3.56461660e-04, 4.56614485e-04,\n","       1.31019690e-04, 2.25346474e+01, 5.17810369e-05, 2.27373696e-02,\n","       1.28920093e+00, 1.39458291e-03, 2.73032607e-02, 6.19396894e-04,\n","       9.37874966e-02, 7.13676378e+01, 2.549970...\n","       1.80541839e-05, 1.38445205e+00, 2.42294898e-05, 1.92992532e+00,\n","       3.29686208e+01, 5.28199561e-03, 3.13283014e-05, 1.70559678e-02,\n","       8.00723392e+01, 4.15799422e-02, 5.49151100e-03, 2.71379372e+01,\n","       3.28577885e-02, 1.76598278e-01, 2.41057562e-05, 1.84555548e-05,\n","       2.42000292e-05, 6.84486965e-03, 4.19723119e+00, 2.74593676e-02,\n","       2.38679011e+00, 7.37128542e-02, 9.39987999e-02, 4.96891052e-02])})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["param_grid = {'C': loguniform.rvs(1e-05, 100, size=200)} # using a log uniform distribution to test different orders of magnitude\n","logreg = LogisticRegression()\n","logreg_grid = GridSearchCV(logreg, param_grid, cv=3)\n","logreg_grid.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"J39zQKd7QLqw"},"source":["We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. LogisticRegression(C=5.2))."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMXaIP7dTbyp","outputId":"56f85b79-760d-4c3c-91be-579ee8ef4148"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=3.4134905785885077)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=3.4134905785885077)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(C=3.4134905785885077)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Fit the logistic regression model\n","logreg_model = logreg_grid.best_estimator_\n","logreg_model"]},{"cell_type":"markdown","metadata":{"id":"OeFkGIhJQREW"},"source":["## Evaluating Model 2\n","So how well does our model do in classifying sentences? One way is to check the accuracy against the testing dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8TLsncnTgmJ","outputId":"b09fd385-dc62-4fbd-e9ff-4cb59b0ca20f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 83.5%\n"]}],"source":["# Evaluate the score of the model\n","y_pred = logreg_model.predict(X_test)\n","accuracy = np.mean(y_pred == y_test)\n","print(f\"Accuracy: {round(accuracy * 100, 2)}%\")"]},{"cell_type":"markdown","metadata":{"id":"SG-tur4cQc2V"},"source":["How good is this score? What can we compare it against? Let's first look at a dummy classifier:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EzAn-f3kT4T8","outputId":"0d3176f4-df7c-43cd-97aa-399dd262e608"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 67.0%\n"]}],"source":["from sklearn.dummy import DummyClassifier\n","clf = DummyClassifier()\n","\n","# Compare your model with a dummy classifier\n","clf.fit(X_train, y_train)\n","clf_pred = clf.predict(X_test)\n","clf_accuracy = np.mean(clf_pred == y_test)\n","print(f\"Accuracy: {round(clf_accuracy * 100, 2)}%\")"]},{"cell_type":"markdown","metadata":{"id":"Ildzqm6RQhGP"},"source":["So our model clearly does better than a dummy classifier"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"930a20a62f4517be0f094e65a315677f4b62e82462652bcc55846e512865d1ae"}}},"nbformat":4,"nbformat_minor":0}