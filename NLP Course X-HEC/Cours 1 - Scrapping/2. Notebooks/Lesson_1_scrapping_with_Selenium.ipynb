{"cells":[{"cell_type":"markdown","id":"1975ce9a","metadata":{"id":"1975ce9a"},"source":["## Selenium presentation, context of use"]},{"cell_type":"markdown","id":"7ca89497","metadata":{"id":"7ca89497"},"source":[">`Selenium`  is a library that allows to control a browser (Chrome, Internet Explorer, Firefox, Safari,...) in an automatic way through a series of programs. Originally created to perform automated Web tests, this package is also used for Webscraping because of its compatibility with JavaScript. This strength makes it a real alternative to `BeautifulSoup` for dynamic Web pages, which are increasingly in the majority.\n","\n","> On the other hand, the use of `Selenium` creates a major constraint: the automated control of browsers requires a lot of resources, thus reducing the efficiency and the speed of execution compared to a library like `BeautifulSoup`.\n","\n","> The use of `Selenium` is therefore recommended (or even essential) for websites using **JavaScript** but is not recommended for retrieving **a large data load**."]},{"cell_type":"markdown","id":"a92e3656","metadata":{"id":"a92e3656"},"source":["### Some introductory html notions "]},{"cell_type":"markdown","id":"edf29048","metadata":{"id":"edf29048"},"source":["It is useful to know the basic concepts of HTML to use Selenium effectively. In particular, here are some points to know:\n","\n","> * **HTML elements:** an HTML document is composed of elements nested within each other. Each element is defined by an opening and closing tag, such as <p> and </p> for a paragraph. Elements can have attributes that define additional properties, such as class or id.\n","> * **The structure of an HTML document:** an HTML document is organized into a set of elements that form a hierarchy. The document has a root, which is the html element, and it can contain two main parts: head and body. The head part contains information about the document, like its title, and the body part contains the content displayed on the screen.\n","> * **CSS selectors:** Selenium uses CSS selectors to find elements on a web page. A CSS selector is a string that allows you to select one or more elements based on their name, class or identifier. For example, the selector \"div.review-card\" selects all div elements that have the class review-card.\n","\n","By knowing these basic HTML concepts, you will be able to understand the structure of a web page and how to select the elements you want with Selenium."]},{"cell_type":"markdown","id":"2ce25620","metadata":{"id":"2ce25620"},"source":["## 1. Discovering and getting started with selenium"]},{"cell_type":"markdown","id":"1c824898","metadata":{"id":"1c824898"},"source":["> The first step to start scraping web sites using `Selenium` is to install the package on your virtual environment. \n","\n","> Run the following cell to install `selenium`."]},{"cell_type":"code","execution_count":null,"id":"1ce7dd59","metadata":{"id":"1ce7dd59","executionInfo":{"status":"ok","timestamp":1675778374848,"user_tz":-60,"elapsed":12031,"user":{"displayName":"Rehan Ibrahim","userId":"00713070218764111941"}},"outputId":"42bc37ec-b96e-40d1-95bc-9751a3f87e67","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting selenium\n","  Downloading selenium-4.8.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Collecting urllib3[socks]~=1.26\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.8/dist-packages (from selenium) (2022.12.7)\n","Collecting trio~=0.17\n","  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 KB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting exceptiongroup>=1.0.0rc9\n","  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Collecting outcome\n","  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n","Collecting async-generator>=1.9\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.10)\n","Collecting sniffio\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (22.2.0)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: urllib3, sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed async-generator-1.10 exceptiongroup-1.1.0 h11-0.14.0 outcome-1.2.0 selenium-4.8.0 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.14 wsproto-1.2.0\n"]}],"source":["!pip install selenium"]},{"cell_type":"code","execution_count":null,"id":"288a5643","metadata":{"id":"288a5643"},"outputs":[],"source":["from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.common.keys import Keys\n","from selenium.common.exceptions import NoSuchElementException\n","\n","# Libraries for the last exercise (optionnal)\n","import os\n","import pandas as pd\n","import time\n","import matplotlib.pyplot as plt\n","import datetime\n","import argparse\n","from bs4 import BeautifulSoup\n","import requests"]},{"cell_type":"markdown","id":"9b6d85c8","metadata":{"id":"9b6d85c8"},"source":["> A **webdriver** is an essential ingredient in this process. It is what will automatically open your browser to access the website of your choice. This step is different depending on the browser you use to explore the internet. For the purpose of this class, we will use Google Chrome. For Chrome, you must first download the webdriver at https://chromedriver.chromium.org/downloads. There are several different download options depending on your version of Chrome. To find out what version of Chrome you have, click on the three vertical dots in the upper right corner of your browser window, scroll down to the help page, and select \"About Google Chrome\".\n",">\n","> Once chromedriver is downloaded, remember to place it at the same level as this notebook otherwise the rest of the instructions will not work.\n",">\n","> We can now initialize our webdriver to navigate on a page of the trustiplot site (https://fr.trustpilot.com/review/engie.fr)\n","\n","> **Instruction: Set a webdriver to access the page https://fr.trustpilot.com/review/engie.fr**"]},{"cell_type":"code","execution_count":null,"id":"5adc77ac","metadata":{"id":"5adc77ac","colab":{"base_uri":"https://localhost:8080/","height":675},"executionInfo":{"status":"error","timestamp":1675779063872,"user_tz":-60,"elapsed":1531,"user":{"displayName":"Rehan Ibrahim","userId":"00713070218764111941"}},"outputId":"bd739194-7209-46e0-f0a6-269727439a83"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-68132b120e41>:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n","  driver = webdriver.Chrome(executable_path=\"C:/Users/Rehan Ibrahim/Downloads/CHROMEDRIVER/chromedriver.exe\")\n"]},{"output_type":"error","ename":"WebDriverException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-68132b120e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C:/Users/Rehan Ibrahim/Downloads/CHROMEDRIVER/chromedriver.exe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://fr.trustpilot.com/review/engie.fr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_log_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             super().__init__(\n\u001b[0m\u001b[1;32m    105\u001b[0m                 command_executor=ChromiumRemoteConnection(\n\u001b[1;32m    106\u001b[0m                     \u001b[0mremote_server_addr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mw3c_caps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_w3c_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw3c_caps\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"sessionId\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: cannot find Chrome binary\nStacktrace:\n#0 0x562360093303 <unknown>\n#1 0x56235fe67d37 <unknown>\n#2 0x56235fe8dba7 <unknown>\n#3 0x56235fe8c330 <unknown>\n#4 0x56235fecd4a6 <unknown>\n#5 0x56235fec4753 <unknown>\n#6 0x56235fe97a14 <unknown>\n#7 0x56235fe98b7e <unknown>\n#8 0x5623600e232e <unknown>\n#9 0x5623600e5c0e <unknown>\n#10 0x5623600c8610 <unknown>\n#11 0x5623600e6c23 <unknown>\n#12 0x5623600ba545 <unknown>\n#13 0x5623601076a8 <unknown>\n#14 0x562360107836 <unknown>\n#15 0x562360122d13 <unknown>\n#16 0x7fb45d96d609 start_thread\n"]}],"source":["# insert your code\n","from selenium import web\n"]},{"cell_type":"markdown","id":"ba2f6d80","metadata":{"id":"ba2f6d80"},"source":["> Once the driver is installed, the first step is to click on the cookies button to continue the navigation. \n","> It is possible to find the path of the button by inspecting it directly: \n",">\n",">\n","> The **`find_element`** function then allows us to search for the element using the located path. All that remains is to click on the button using the **`click`** function. Here is an example of code:\n",">\n",">```python\n",">cookie_button = driver.find_element(By.XPATH,cookie_button_path)\n",">cookie_button.click()\n",">```\n",">\n",">  **Instruction : using the example provided, inspect the web page to find the path to the cookie \"ok\" button and click it.**"]},{"cell_type":"code","execution_count":null,"id":"2414952e","metadata":{"id":"2414952e"},"outputs":[],"source":["# insert your code\n","cookie_button = driver.find_element(By.XPATH,'//*[@id=\"onetrust-accept-btn-handler\"]')\n","cookie_button.click()"]},{"cell_type":"markdown","id":"e92c9776","metadata":{"id":"e92c9776"},"source":["> **Instruction: start by retrieving the title of the website's first comment.**\n","> \n","> In the same way as for the button of validation of the cookies, it is necessary at first to inspect the web page: \n",">\n","> Then all that remains is to retrieve the text of the element found. Here is an example of code : \n",">\n","> ``title = driver.find_element(By.XPATH,title_path).text``"]},{"cell_type":"code","execution_count":null,"id":"4cc4f2f2","metadata":{"id":"4cc4f2f2"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"fa28d853","metadata":{"id":"fa28d853"},"source":["> **Instruction**\n",">\n","> **On the same basis:**\n","> * Retrieve the body text of the first comment.\n","> * Retrieve the date of the first comment.\n","> * Retrieve the note of the first comment."]},{"cell_type":"code","execution_count":null,"id":"2fcf0948","metadata":{"id":"2fcf0948"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"032af50f","metadata":{"id":"032af50f"},"source":["> Now that we have extracted some basic elements from the first page of the website https://fr.trustpilot.com/review/engie.fr, we would like to extract the same information but from the second page. \n",">\n","> First we will extract the maximum number of pages we can navigate in. We will be able to make sure that we have at least 2 pages on the site.\n",">\n","> To find out the maximum number of pages on the site, you can search by inspecting the button on the last page.\n",">\n","> **Instruction: extract the number of pages of the site https://fr.trustpilot.com/review/engie.fr and check that we have at least two pages on the site.**"]},{"cell_type":"code","execution_count":null,"id":"10c6bba0","metadata":{"id":"10c6bba0"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"6d45b66e","metadata":{"id":"6d45b66e"},"source":["> **Instruction: by inspecting the first page of the site https://fr.trustpilot.com/review/engie.fr, identify the location of the button to go to the next page and click on it (as previously done with the cookies button).**"]},{"cell_type":"code","execution_count":null,"id":"fad24322","metadata":{"id":"fad24322"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"e691f906","metadata":{"id":"e691f906"},"source":["> **Instruction - Once on page 2 of https://fr.trustpilot.com/review/engie.fr, as for the first page, extract the following information:**\n","\n","> * The title of the first comment.\n","> * The content of the first comment.\n","> * The date of the first comment."]},{"cell_type":"code","execution_count":null,"id":"b60550d1","metadata":{"id":"b60550d1"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"ef9dcbc1","metadata":{"id":"ef9dcbc1"},"source":["> **Instruction: extract the content of all the comments on page 2 of the site.**"]},{"cell_type":"code","execution_count":null,"id":"af0d7d93","metadata":{"id":"af0d7d93"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"d2b16d4e","metadata":{"id":"d2b16d4e"},"source":["## 2. Exploitation and use of the extracted data"]},{"cell_type":"markdown","id":"ee436cf5","metadata":{"id":"ee436cf5"},"source":["> On this 2nd part, we will focus on a second website which is \"Avis Vérifiés\" for the same company: https://www.avis-verifies.com/avis-clients/engie-homeservices.fr\n","\n","> The code you will write will be to open a connection to a MySQL database, create a \"reviews\" table if it doesn't already exist, then use Selenium (as above) to open a Chrome browser and retrieve the reviews on all the available pages. \n","\n","> For each review, we will store the rating, the text and the date in the \"reviews\" table in the database."]},{"cell_type":"markdown","id":"78c7cad2","metadata":{"id":"78c7cad2"},"source":["### Option 1 - reviews list"]},{"cell_type":"code","execution_count":null,"id":"2bd39b25","metadata":{"id":"2bd39b25"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"81640680","metadata":{"id":"81640680"},"source":["### Option 2 - SQLite "]},{"cell_type":"markdown","id":"77f05105","metadata":{"id":"77f05105"},"source":["> **Instruction : import the necessary libraries, create the database connection and set up the webdriver**"]},{"cell_type":"code","execution_count":null,"id":"8d1515d5","metadata":{"id":"8d1515d5"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"fa214efb","metadata":{"id":"fa214efb"},"source":["> **Instruction : Go to the website and accept the cookie by clicking on the cookie button**"]},{"cell_type":"code","execution_count":null,"id":"0007987e","metadata":{"id":"0007987e"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"cc62cb5c","metadata":{"id":"cc62cb5c"},"source":["> **Instruction: we would like to extract the evaluation data (review rating, review text and review date) from all pages of the website, starting from the first page and continuing to the last page.**"]},{"cell_type":"code","execution_count":null,"id":"08c17b33","metadata":{"id":"08c17b33"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"80f79114","metadata":{"id":"80f79114"},"source":["This code will retrieve assessment data from all pages of the website, starting with the first page and continuing to the last page. At each iteration of the loop, it retrieves the data from the current page, inserts it into the database, and then clicks the \"next page\" button to move to the next page. When the \"next page\" button cannot be found the loop ends."]},{"cell_type":"markdown","id":"b4ab8fea","metadata":{"id":"b4ab8fea"},"source":["We will try to leverage on the extracted database and detect negative comments.  \n",">\n","> **Instruction: Develop a generic approach to detect negative comments.**"]},{"cell_type":"code","execution_count":null,"id":"e21029e0","metadata":{"id":"e21029e0"},"outputs":[],"source":["# insert your code\n"]},{"cell_type":"markdown","id":"8766dced","metadata":{"id":"8766dced"},"source":["This code opens a connection to a MySQL database, runs a query to select the negative reviews (rating below 3) from the \"reviews\" table, then displays the rating and text of each review."]},{"cell_type":"markdown","id":"48078ff3","metadata":{"id":"48078ff3"},"source":["You can modify this query to search for specific keywords in the text of the notices. For example, to search for notices containing the words \"à fuir\", you can write:"]},{"cell_type":"code","execution_count":null,"id":"28b14788","metadata":{"id":"28b14788"},"outputs":[],"source":["Q = \"SELECT * FROM reviews WHERE review_text LIKE '%à fuir%'\""]},{"cell_type":"markdown","id":"84cc9ee8","metadata":{"id":"84cc9ee8"},"source":["## 3. Bonus"]},{"cell_type":"markdown","id":"a2900842","metadata":{"id":"a2900842"},"source":["Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. Selenium, on the other hand, is a browser automation tool that is used to automate web browsers.\n","\n","When used together, Selenium can be used to open a web page and interact with its contents, and then Beautiful Soup can be used to extract the desired information from the page. For example, Selenium can be used to click on a button to load more data on a page, and then Beautiful Soup can be used to extract the data that was loaded."]},{"cell_type":"markdown","id":"fd45d58b","metadata":{"id":"fd45d58b"},"source":["> Instruction\n","> * Scrape all the ads of apartments for rent or sale in the city of Paris.\n",">\n","> * Extract the following information for each ad: the title, location, surface and price.\n",">\n","> * Store the extracted information in a CSV file."]},{"cell_type":"markdown","id":"4fe06663","metadata":{"id":"4fe06663"},"source":["NB: it is possible that the site blocks your IP address if the code runs several times"]},{"cell_type":"code","execution_count":null,"id":"a42ed841","metadata":{"id":"a42ed841"},"outputs":[],"source":["# insert your code\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"34d3564aebb0ad63b6673275ac6fa9b7422ce122acee802f48c8e7274557cb2a"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}